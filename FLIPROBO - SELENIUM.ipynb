{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bd94e08",
   "metadata": {},
   "source": [
    "# WEB SCRAPING – ASSIGNMENT 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c156570",
   "metadata": {},
   "source": [
    "<b>Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10\n",
    "jobs data.\n",
    "This task will be done in following steps:</b>        \n",
    "<b>1. First get the webpage https://www.naukri.com/           \n",
    "2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the location” field.  \n",
    "3. Then click the search button.          \n",
    "4. Then scrape the data for the first 10 jobs results you get.      \n",
    "5. Finally create a dataframe of the scraped data.     \n",
    "Note: All of the above steps have to be done in code. No step is to be done manually.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3500448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d3a3211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets first connect to the driver\n",
    "\n",
    "driver = webdriver.Chrome(r\"C:\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "403623a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the naukri page on automated chrome browser\n",
    "\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e605418f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering “Data Analyst” in “Skill,Designations,Companies” field\n",
    "\n",
    "designation = driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bee3829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering “Bangalore” in “Location” field\n",
    "\n",
    "location = driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac4015a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking the search button\n",
    "\n",
    "search = driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f612f723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty lists for scraping data\n",
    "\n",
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "experience_required = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3596d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Job title from the given page\n",
    "\n",
    "title_tags = driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title = i.text\n",
    "    job_title.append(title)\n",
    "\n",
    "    \n",
    "# Scraping Job Location from the given page\n",
    "\n",
    "location_tags = driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location = i.text\n",
    "    job_location.append(location)\n",
    "\n",
    "\n",
    "# Scraping Company Name from the given page\n",
    "\n",
    "company_tags = driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company = i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "    \n",
    "# Scraping Job Experience from the given page\n",
    "\n",
    "experience_tags = driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience = i.text\n",
    "    experience_required.append(experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ab98f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "# Printing the length of the scraped data\n",
    "\n",
    "print(len(job_title), len(job_location), len(company_name), len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16f1f191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Exp_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Chennai</td>\n",
       "      <td>Latentview</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Mangaluru/Mangalore, Pune...</td>\n",
       "      <td>Coresight Research, Inc.</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Varite</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst - CRM Platform</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>Artech infosystem</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Jar</td>\n",
       "      <td>0-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hiring For Data Analyst (DA)/ Team Lead (TL) -...</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...</td>\n",
       "      <td>Cognizant</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Call For Clinical Data Analyst - Hyd/Bangalore...</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...</td>\n",
       "      <td>Cognizant</td>\n",
       "      <td>6-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Payroll Transformation Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Arrow Electronics</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Payroll Transformation Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Arrow Electronics</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Master Data Management Business Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0                                Senior Data Analyst   \n",
       "1                                       Data Analyst   \n",
       "2                                       Data Analyst   \n",
       "3                        Data Analyst - CRM Platform   \n",
       "4                                       Data Analyst   \n",
       "5  Hiring For Data Analyst (DA)/ Team Lead (TL) -...   \n",
       "6  Call For Clinical Data Analyst - Hyd/Bangalore...   \n",
       "7                Payroll Transformation Data Analyst   \n",
       "8                Payroll Transformation Data Analyst   \n",
       "9            Master Data Management Business Analyst   \n",
       "\n",
       "                                        Job_location  \\\n",
       "0                       Bangalore/Bengaluru, Chennai   \n",
       "1  Bangalore/Bengaluru, Mangaluru/Mangalore, Pune...   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5  Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...   \n",
       "6  Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "               Company_name Exp_required  \n",
       "0                Latentview      3-6 Yrs  \n",
       "1  Coresight Research, Inc.      4-8 Yrs  \n",
       "2                    Varite      2-5 Yrs  \n",
       "3         Artech infosystem      1-6 Yrs  \n",
       "4                       Jar      0-4 Yrs  \n",
       "5                 Cognizant      3-8 Yrs  \n",
       "6                 Cognizant      6-9 Yrs  \n",
       "7         Arrow Electronics     5-10 Yrs  \n",
       "8         Arrow Electronics      3-7 Yrs  \n",
       "9                 Accenture      6-8 Yrs  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the dataframe from above data\n",
    "\n",
    "df = pd.DataFrame({'Job_title':job_title, 'Job_location':job_location, 'Company_name':company_name, 'Exp_required':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b9264a",
   "metadata": {},
   "source": [
    "<b>Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:</b>      \n",
    "<b>1. First get the webpage https://www.naukri.com/          \n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the location” field.  \n",
    "3. Then click the search button.           \n",
    "4. Then scrape the data for the first 10 jobs results you get.           \n",
    "5. Finally create a dataframe of the scraped data.          \n",
    "Note: All of the above steps have to be done in code. No step is to be done manually.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb5ae1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets first connect to the driver\n",
    "\n",
    "driver = webdriver.Chrome(r\"C:\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7da643f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the webpage on automated chrome browser\n",
    "\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5d0be10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entering “Data Scientist” in “Skill,Designations,Companies” field\n",
    "\n",
    "designation = driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f787e03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering “Bangalore” in “Location” field\n",
    "\n",
    "location = driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd0b4ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking the search button\n",
    "\n",
    "search = driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "214368da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty lists for scraping data\n",
    "\n",
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "experience_required = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d1d13fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Job title from the given page\n",
    "\n",
    "title_tags = driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title = i.text\n",
    "    job_title.append(title)\n",
    "\n",
    "    \n",
    "# Scraping Job Location from the given page\n",
    "\n",
    "location_tags = driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location = i.text\n",
    "    job_location.append(location)\n",
    "\n",
    "\n",
    "# Scraping Company Name from the given page\n",
    "\n",
    "company_tags = driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company = i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "    \n",
    "# Scraping Job Experience from the given page\n",
    "\n",
    "experience_tags = driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience = i.text\n",
    "    experience_required.append(experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "013352fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "# Printing the length of the scraped data\n",
    "\n",
    "print(len(job_title), len(job_location), len(company_name), len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "727b7296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Exp_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science Manager</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mongodb Database Administrator, Maria DB or Ca...</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad, P...</td>\n",
       "      <td>Mphasis</td>\n",
       "      <td>9-14 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Assistant Manager - Data Science</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Pune</td>\n",
       "      <td>CitiusTech</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, New Delhi, Pune, Gurgaon/...</td>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad, P...</td>\n",
       "      <td>Tech Mahindra</td>\n",
       "      <td>10-14 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, New Delhi, Chennai</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist: Artificial Intelligence</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist - Computer Vision</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Pune, Chennai</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>8-13 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0                            Data Science Specialist   \n",
       "1                               Data Science Manager   \n",
       "2  Mongodb Database Administrator, Maria DB or Ca...   \n",
       "3                   Assistant Manager - Data Science   \n",
       "4                                     Data Scientist   \n",
       "5                                     Data Scientist   \n",
       "6                              Senior Data Scientist   \n",
       "7            Data Scientist: Artificial Intelligence   \n",
       "8                   Data Scientist - Computer Vision   \n",
       "9                              Senior Data Scientist   \n",
       "\n",
       "                                        Job_location             Company_name  \\\n",
       "0  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...                Accenture   \n",
       "1  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...                Accenture   \n",
       "2  Bangalore/Bengaluru, Hyderabad/Secunderabad, P...                  Mphasis   \n",
       "3                  Bangalore/Bengaluru, Mumbai, Pune               CitiusTech   \n",
       "4  Bangalore/Bengaluru, New Delhi, Pune, Gurgaon/...            ZS Associates   \n",
       "5  Bangalore/Bengaluru, Hyderabad/Secunderabad, P...            Tech Mahindra   \n",
       "6    Bangalore/Bengaluru, Mumbai, New Delhi, Chennai  Boston Consulting Group   \n",
       "7                                Bangalore/Bengaluru                      IBM   \n",
       "8                                Bangalore/Bengaluru                  Walmart   \n",
       "9                 Bangalore/Bengaluru, Pune, Chennai                    Wipro   \n",
       "\n",
       "  Exp_required  \n",
       "0      2-4 Yrs  \n",
       "1      4-7 Yrs  \n",
       "2     9-14 Yrs  \n",
       "3      5-9 Yrs  \n",
       "4      5-8 Yrs  \n",
       "5    10-14 Yrs  \n",
       "6     5-10 Yrs  \n",
       "7      4-8 Yrs  \n",
       "8      3-7 Yrs  \n",
       "9     8-13 Yrs  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the dataframe from above data\n",
    "\n",
    "df = pd.DataFrame({'Job_title':job_title, 'Job_location':job_location, 'Company_name':company_name, 'Exp_required':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd7a054",
   "metadata": {},
   "source": [
    "<b>Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:</b>\n",
    "<b>1. first get the webpage https://www.naukri.com/        \n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.          \n",
    "3. Then click the search button.           \n",
    "4. Then apply the location filter and salary filter by checking the respective boxes          \n",
    "5. Then scrape the data for the first 10 jobs results you get.        \n",
    "6. Finally create a dataframe of the scraped data.          \n",
    "Note: All of the above steps have to be done in code. No step is to be done manually.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0de04d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets first connect to the driver\n",
    "\n",
    "driver = webdriver.Chrome(r\"C:\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "426fca7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the webpage on automated chrome browser\n",
    "\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1eef9dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering “Data Scientist” in “Skill,Designations,Companies” field\n",
    "\n",
    "designation = driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ceea51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking the search button\n",
    "\n",
    "search = driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ffcee3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty lists for scraping data\n",
    "\n",
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "experience_required = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd98952a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the delhi/ncr check box\n",
    "\n",
    "location = driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/section[1]/div[2]/div[6]/div[2]/div[3]/label/p\")\n",
    "location.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b9567b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the salary check box\n",
    "\n",
    "salary = driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/section[1]/div[2]/div[2]/div[2]/div[1]/label/p\")\n",
    "salary.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "615e98c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Job title from the given page\n",
    "\n",
    "title_tags = driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title = i.text\n",
    "    job_title.append(title)\n",
    "\n",
    "    \n",
    "# Scraping Job Location from the given page\n",
    "\n",
    "location_tags = driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location = i.text\n",
    "    job_location.append(location)\n",
    "\n",
    "\n",
    "# Scraping Company Name from the given page\n",
    "\n",
    "company_tags = driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company = i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "    \n",
    "# Scraping Job Experience from the given page\n",
    "\n",
    "experience_tags = driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience = i.text\n",
    "    experience_required.append(experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d507d231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "# Printing the length of the scraped data\n",
    "\n",
    "print(len(job_title), len(job_location), len(company_name), len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f72bd765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Exp_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science Specialist</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science Manager</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mongodb Database Administrator, Maria DB or Ca...</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Chennai, Bangalo...</td>\n",
       "      <td>Mphasis</td>\n",
       "      <td>9-14 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Assistant Manager - Data Science</td>\n",
       "      <td>Mumbai, Pune, Bangalore/Bengaluru</td>\n",
       "      <td>CitiusTech</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New Delhi, Pune, Gurgaon/Gurugram, Bangalore/B...</td>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Mumbai, New Delhi, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Chennai, Bangalo...</td>\n",
       "      <td>Tech Mahindra</td>\n",
       "      <td>10-14 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist: Artificial Intelligence</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist - Computer Vision</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Pune, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>8-13 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0                            Data Science Specialist   \n",
       "1                               Data Science Manager   \n",
       "2  Mongodb Database Administrator, Maria DB or Ca...   \n",
       "3                   Assistant Manager - Data Science   \n",
       "4                                     Data Scientist   \n",
       "5                              Senior Data Scientist   \n",
       "6                                     Data Scientist   \n",
       "7            Data Scientist: Artificial Intelligence   \n",
       "8                   Data Scientist - Computer Vision   \n",
       "9                              Senior Data Scientist   \n",
       "\n",
       "                                        Job_location             Company_name  \\\n",
       "0  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...                Accenture   \n",
       "1  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...                Accenture   \n",
       "2  Hyderabad/Secunderabad, Pune, Chennai, Bangalo...                  Mphasis   \n",
       "3                  Mumbai, Pune, Bangalore/Bengaluru               CitiusTech   \n",
       "4  New Delhi, Pune, Gurgaon/Gurugram, Bangalore/B...            ZS Associates   \n",
       "5    Mumbai, New Delhi, Chennai, Bangalore/Bengaluru  Boston Consulting Group   \n",
       "6  Hyderabad/Secunderabad, Pune, Chennai, Bangalo...            Tech Mahindra   \n",
       "7                                Bangalore/Bengaluru                      IBM   \n",
       "8                                Bangalore/Bengaluru                  Walmart   \n",
       "9                 Pune, Chennai, Bangalore/Bengaluru                    Wipro   \n",
       "\n",
       "  Exp_required  \n",
       "0      2-4 Yrs  \n",
       "1      4-7 Yrs  \n",
       "2     9-14 Yrs  \n",
       "3      5-9 Yrs  \n",
       "4      5-8 Yrs  \n",
       "5     5-10 Yrs  \n",
       "6    10-14 Yrs  \n",
       "7      4-8 Yrs  \n",
       "8      3-7 Yrs  \n",
       "9     8-13 Yrs  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the dataframe from above data\n",
    "\n",
    "df = pd.DataFrame({'Job_title':job_title, 'Job_location':job_location, 'Company_name':company_name, 'Exp_required':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9901a52d",
   "metadata": {},
   "source": [
    "<b>Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:       \n",
    "<b>1. Brand       \n",
    "2. Product Description         \n",
    "3. Price          \n",
    "The attributes which you have to scrape is ticked marked in the below image</b>\n",
    "\n",
    "<b>To scrape the data you have to go through following steps:</b>\n",
    "\n",
    "<b>1. Go to Flipkart webpage by url : https://www.flipkart.com/</b>        \n",
    "<b>2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and click the search icon</b>        \n",
    "<b>3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the required data as usual.</b>     \n",
    "<b>4. After scraping data from the first page, go to the “Next” Button at the bottom other page , then\n",
    "click on it.</b>           \n",
    "<b>5. Now scrape data from this page as usual</b>           \n",
    "<b>6. Repeat this until you get data for 100 sunglasses.</b>\n",
    "\n",
    "<b>Note: That all of the above steps have to be done by coding only and not manually.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "91e7ddec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets first connect to the driver\n",
    "\n",
    "driver = webdriver.Chrome(r\"C:\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "70187009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the webpage on automated chrome browser\n",
    "\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ff04aaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering “Sunglasses” in “Products/Brands and More\"\n",
    "\n",
    "product = driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "product.send_keys('Sunglasses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d4f69f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking the search button\n",
    "\n",
    "search = driver.find_element(By.XPATH,'//button[@class=\"L0Z3Pu\"]')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6dcd8d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty lists for scraping data\n",
    "\n",
    "brand = []\n",
    "product_description =[]\n",
    "price = []\n",
    "discount = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8862bc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting all the tags\n",
    "\n",
    "start = 0\n",
    "end = 3\n",
    "\n",
    "for page in range(start,end):\n",
    "    brand_name = driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brand_name:\n",
    "        brand.append(i.text)\n",
    "    \n",
    "    product_desc = driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for i in product_desc:\n",
    "        product_description.append(i.text)\n",
    "    \n",
    "    product_price = driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for i in product_price:\n",
    "        price.append(i.text)\n",
    "    \n",
    "    product_discount = driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]')\n",
    "    for i in product_discount:\n",
    "        discount.append(i.text)\n",
    "    \n",
    "    \n",
    "    next_button = driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')  # to scrap data from next pages\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "70ffd9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 120 120 120\n"
     ]
    }
   ],
   "source": [
    "# Printing the length of the scraped data\n",
    "\n",
    "print(len(brand), len(product_description), len(price), len(discount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ab6523ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection Aviator Sunglasses (55)</td>\n",
       "      <td>₹649</td>\n",
       "      <td>74% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Round Sunglasses (Free...</td>\n",
       "      <td>₹399</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹799</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>UV Protection Aviator Sunglasses (57)</td>\n",
       "      <td>₹198</td>\n",
       "      <td>73% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LIZA ANGEL</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹199</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Retro Squ...</td>\n",
       "      <td>₹999</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Cat-eye S...</td>\n",
       "      <td>₹599</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>SHAAH COLLECTIONS</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>₹179</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>New Specs</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹264</td>\n",
       "      <td>89% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>UV Protection Round Sunglasses (47)</td>\n",
       "      <td>₹649</td>\n",
       "      <td>67% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Brand                                Product Description  \\\n",
       "0      ROZZETTA CRAFT              UV Protection Aviator Sunglasses (55)   \n",
       "1      ROZZETTA CRAFT  UV Protection, Gradient Round Sunglasses (Free...   \n",
       "2            Fastrack      UV Protection Wayfarer Sunglasses (Free Size)   \n",
       "3               NuVew              UV Protection Aviator Sunglasses (57)   \n",
       "4          LIZA ANGEL      UV Protection Wayfarer Sunglasses (Free Size)   \n",
       "..                ...                                                ...   \n",
       "95      VINCENT CHASE  by Lenskart Polarized, UV Protection Retro Squ...   \n",
       "96      VINCENT CHASE  by Lenskart Polarized, UV Protection Cat-eye S...   \n",
       "97  SHAAH COLLECTIONS              UV Protection Aviator Sunglasses (54)   \n",
       "98          New Specs   UV Protection Rectangular Sunglasses (Free Size)   \n",
       "99      VINCENT CHASE                UV Protection Round Sunglasses (47)   \n",
       "\n",
       "   Price Discount  \n",
       "0   ₹649  74% off  \n",
       "1   ₹399  80% off  \n",
       "2   ₹799  20% off  \n",
       "3   ₹198  73% off  \n",
       "4   ₹199  50% off  \n",
       "..   ...      ...  \n",
       "95  ₹999  50% off  \n",
       "96  ₹599  70% off  \n",
       "97  ₹179  82% off  \n",
       "98  ₹264  89% off  \n",
       "99  ₹649  67% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating dataframe for the first 100 sunglasses \n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['Brand'] = brand[0:100]\n",
    "df['Product Description'] = product_description[0:100]\n",
    "df['Price'] = price[0:100]\n",
    "df['Discount'] = discount[0:100]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1123f0",
   "metadata": {},
   "source": [
    "<b>Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone.\n",
    "This task will be done in following steps:        \n",
    "<b>1. First get the webpage https://www.flipkart.com/</b>          \n",
    "<b>2. Enter “iphone 11” in “Search” field.</b>        \n",
    "<b>3. Then click the search button.</b>\n",
    "\n",
    "<b>You will reach to the below shown webpage.</b>\n",
    "\n",
    "<b>As shown in the above page you have to scrape the tick marked attributes.These are:</b>         \n",
    "<b>1. Rating</b>          \n",
    "<b>2. Review summary</b>              \n",
    "<b>3. Full review</b>         \n",
    "<b>4. You have to scrape this data for first 100 reviews.</b>\n",
    "\n",
    "<b>Note: All the steps required during scraping should be done through code only and not manually.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b3ab0d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets first connect to the driver\n",
    "\n",
    "driver = webdriver.Chrome(r\"C:\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a7d61bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the webpage on automated chrome browser\n",
    "\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "23c7351a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering “iphone 11” in “Products/Brands and More\"\n",
    "\n",
    "product = driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "product.send_keys('iphone 11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7cb9c61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking the search button\n",
    "\n",
    "search = driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dc2cc592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking the first iphone 11\n",
    "\n",
    "first_iphone11 = driver.find_element(By.XPATH,'//div[@class=\"_4rR01T\"]')\n",
    "first_iphone11.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c0258640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty lists for scraping data\n",
    "\n",
    "rating = []\n",
    "review_summary = []\n",
    "full_review = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "92eeadf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting all the tags\n",
    "\n",
    "start = 0\n",
    "end = 10\n",
    "\n",
    "for page in range(start,end):\n",
    "    product_rating = driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for i in product_rating:\n",
    "        rating.append(i.text)\n",
    "    \n",
    "    product_review_summary = driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for i in product_review_summary:\n",
    "        review_summary.append(i.text)\n",
    "    \n",
    "    product_full_review = driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "    for i in product_full_review:\n",
    "        full_review.append(i.text)\n",
    "    \n",
    "     \n",
    "    next_button = driver.find_element(By.CLASS_NAME,\"ge-49M\")  # to scrap data from next pages\n",
    "    next_button.click()\n",
    "    time.sleep(3)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c8e198f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Full review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>After using 3 years mobile review. Excellent &amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>I am using the phone for last 5 years and foun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Don't waste your money</td>\n",
       "      <td>Very bad mic within 2 days my phone mic is not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Good quality product</td>\n",
       "      <td>impressively Nice......\\nOne of the greatest i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>Fantastic and prompt delivery.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>After using 3 years mobile review. Excellent &amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>I am using the phone for last 5 years and foun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Don't waste your money</td>\n",
       "      <td>Very bad mic within 2 days my phone mic is not...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating          Review Summary  \\\n",
       "0       5        Perfect product!   \n",
       "1       5                Terrific   \n",
       "2       5          Simply awesome   \n",
       "3       4  Don't waste your money   \n",
       "4       5    Good quality product   \n",
       "..    ...                     ...   \n",
       "95      5   Mind-blowing purchase   \n",
       "96      5        Perfect product!   \n",
       "97      5                Terrific   \n",
       "98      5          Simply awesome   \n",
       "99      5  Don't waste your money   \n",
       "\n",
       "                                          Full review  \n",
       "0   After using 3 years mobile review. Excellent &...  \n",
       "1   I am using the phone for last 5 years and foun...  \n",
       "2   Really satisfied with the Product I received.....  \n",
       "3   Very bad mic within 2 days my phone mic is not...  \n",
       "4   impressively Nice......\\nOne of the greatest i...  \n",
       "..                                                ...  \n",
       "95                     Fantastic and prompt delivery.  \n",
       "96  After using 3 years mobile review. Excellent &...  \n",
       "97  I am using the phone for last 5 years and foun...  \n",
       "98  Really satisfied with the Product I received.....  \n",
       "99  Very bad mic within 2 days my phone mic is not...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating dataframe for the first 100 iphone 11\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['Rating'] = rating[0:100]\n",
    "df['Review Summary'] = review_summary[0:100]\n",
    "df['Full review'] = full_review[0:100]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf12918a",
   "metadata": {},
   "source": [
    "<b>Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the\n",
    "search field.\n",
    "You have to scrape 4 attributes of each sneaker:</b>         \n",
    "<b>1. Brand</b>          \n",
    "<b>2. Product Description</b>        \n",
    "<b>3. Price</b>\n",
    "\n",
    "<b>As shown in the below image, you have to scrape the tick marked attributes.</b>\n",
    "\n",
    "<b>Note: All the steps required during scraping should be done through code only and not manually</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "744aae6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets first connect to the driver\n",
    "\n",
    "driver = webdriver.Chrome(r\"C:\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a332f27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the webpage on automated chrome browser\n",
    "\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b86175d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering “sneakers” in the search field\n",
    "\n",
    "product = driver.find_element(By.CLASS_NAME,'_3704LK')\n",
    "product.send_keys('sneakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a74b25d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking the search button\n",
    "\n",
    "search = driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "46090bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty lists for scraping data\n",
    "\n",
    "brand = []\n",
    "product_description = []\n",
    "price = []\n",
    "discount = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f7667dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting all the tags\n",
    "\n",
    "start = 0\n",
    "end = 3\n",
    "\n",
    "for page in range(start,end):\n",
    "    product_brand = driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in product_brand:\n",
    "        brand.append(i.text)\n",
    "    \n",
    "    product_desc = driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for i in product_desc:\n",
    "        product_description.append(i.text)\n",
    "    \n",
    "    product_price = driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for i in product_price:\n",
    "        price.append(i.text)\n",
    "    \n",
    "    product_discount = driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]')\n",
    "    for i in product_discount:\n",
    "        discount.append(i.text)     \n",
    "    \n",
    "    \n",
    "    next_button = driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')  # to scrap data from next pages\n",
    "    next_button.click()\n",
    "    time.sleep(3)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d98e573c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RapidBox</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹590</td>\n",
       "      <td>40% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TR</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹338</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Labbin</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Modern Trendy Shoes Sneakers For Men</td>\n",
       "      <td>₹470</td>\n",
       "      <td>63% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Lightweight Pack Of 1 Trendy Sneakers Sneakers...</td>\n",
       "      <td>₹259</td>\n",
       "      <td>56% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>SIBROZ</td>\n",
       "      <td>Original Luxury Branded Fashionable Men's Casu...</td>\n",
       "      <td>₹449</td>\n",
       "      <td>61% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Magnolia</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹389</td>\n",
       "      <td>42% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Deals4you</td>\n",
       "      <td>denim fabric shoes men and boys canvas sneaker...</td>\n",
       "      <td>₹289</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>World Wear Footwear</td>\n",
       "      <td>Stylish &amp; Trending Outdoor Walking Comfortable...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>63% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>3SIX5</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹360</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Brand                                Product Description  \\\n",
       "0              RapidBox                                   Sneakers For Men   \n",
       "1                    TR                                   Sneakers For Men   \n",
       "2                Labbin                                   Sneakers For Men   \n",
       "3                BRUTON               Modern Trendy Shoes Sneakers For Men   \n",
       "4                BRUTON  Lightweight Pack Of 1 Trendy Sneakers Sneakers...   \n",
       "..                  ...                                                ...   \n",
       "95               SIBROZ  Original Luxury Branded Fashionable Men's Casu...   \n",
       "96             Magnolia                                   Sneakers For Men   \n",
       "97            Deals4you  denim fabric shoes men and boys canvas sneaker...   \n",
       "98  World Wear Footwear  Stylish & Trending Outdoor Walking Comfortable...   \n",
       "99                3SIX5                                   Sneakers For Men   \n",
       "\n",
       "   Price Discount  \n",
       "0   ₹590  40% off  \n",
       "1   ₹338  77% off  \n",
       "2   ₹499  50% off  \n",
       "3   ₹470  63% off  \n",
       "4   ₹259  56% off  \n",
       "..   ...      ...  \n",
       "95  ₹449  61% off  \n",
       "96  ₹389  42% off  \n",
       "97  ₹289  50% off  \n",
       "98  ₹499  63% off  \n",
       "99  ₹360  75% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating dataframe for the first 100 sneakers\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['Brand'] = brand[0:100]\n",
    "df['Product Description'] = product_description[0:100]\n",
    "df['Price'] = price[0:100]\n",
    "df['Discount'] = discount[0:100]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb52ac4",
   "metadata": {},
   "source": [
    "<b>Q7: Go to the link - https://www.myntra.com/shoes\n",
    "Set second Price filter and Color filter to “Black”, as shown in the below image.</b>\n",
    "\n",
    "<b>And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe\n",
    "description, price of the shoe as shown in the below image.</b>\n",
    "\n",
    "<b>Note: Applying the filter and scraping the data, everything should be done through code only and there\n",
    "should not be any manual step.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6c5d44ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets first connect to the driver\n",
    "\n",
    "driver = webdriver.Chrome(r\"C:\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "164418d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the webpage on automated chrome browser\n",
    "\n",
    "driver.get(\"https://www.myntra.com/shoes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "60b74256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the second Price filter by clicking it\n",
    "\n",
    "price_filter = driver.find_element(By.XPATH,\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label\")\n",
    "price_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d7ba4e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the Color filter to “Black”  by clicking it\n",
    "\n",
    "color_filter = driver.find_element(By.XPATH,\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label/div\")\n",
    "color_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "329ccf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty lists for scraping data\n",
    "\n",
    "brand = []\n",
    "shoe_description = []\n",
    "price = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "57c5fa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting all the tags\n",
    "\n",
    "start = 0\n",
    "end = 4\n",
    "\n",
    "for page in range(start,end):\n",
    "    product_brand = driver.find_elements(By.XPATH,'//h3[@class=\"product-brand\"]')\n",
    "    for i in product_brand:\n",
    "        brand.append(i.text)\n",
    "    \n",
    "    shoe_desc = driver.find_elements(By.XPATH,'//h4[@class=\"product-product\"]')\n",
    "    for i in shoe_desc:\n",
    "        shoe_description.append(i.text)\n",
    "    \n",
    "    product_price = driver.find_elements(By.XPATH,'//div[@class=\"product-price\"]')\n",
    "    for i in product_price:\n",
    "        price.append(i.text)\n",
    "    \n",
    "\n",
    "    next_button = driver.find_element(By.XPATH,'//li[@class=\"pagination-next\"]')  # to scrap data from next pages\n",
    "    next_button.click()\n",
    "    time.sleep(3)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5946f042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Shoe Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Men HOVR SonicSE Running Shoes</td>\n",
       "      <td>Rs. 8499Rs. 9999(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Men ChargedEscape 3 BL Running</td>\n",
       "      <td>Rs. 7199Rs. 8999(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Unisex 3ZER0 IV Basketball</td>\n",
       "      <td>Rs. 7649Rs. 8999(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Men GO WALK - TERRA Shoes</td>\n",
       "      <td>Rs. 8499Rs. 9999(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Fuse 2.0 Training Shoes</td>\n",
       "      <td>Rs. 6399Rs. 7999(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Men Sports Shoes</td>\n",
       "      <td>Rs. 8499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Textured Block Sandals</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Tommy Hilfiger</td>\n",
       "      <td>Men Leather Sneakers</td>\n",
       "      <td>Rs. 6509Rs. 9299(30% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Women Leather Horsebit Loafers</td>\n",
       "      <td>Rs. 11999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>fitflop</td>\n",
       "      <td>Embellished PU Comfort Pumps</td>\n",
       "      <td>Rs. 7499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                Shoe Description                      Price\n",
       "0     UNDER ARMOUR  Men HOVR SonicSE Running Shoes  Rs. 8499Rs. 9999(15% OFF)\n",
       "1     UNDER ARMOUR  Men ChargedEscape 3 BL Running  Rs. 7199Rs. 8999(20% OFF)\n",
       "2     UNDER ARMOUR      Unisex 3ZER0 IV Basketball  Rs. 7649Rs. 8999(15% OFF)\n",
       "3         Skechers       Men GO WALK - TERRA Shoes  Rs. 8499Rs. 9999(15% OFF)\n",
       "4             Puma     Men Fuse 2.0 Training Shoes  Rs. 6399Rs. 7999(20% OFF)\n",
       "..             ...                             ...                        ...\n",
       "95        Skechers                Men Sports Shoes                   Rs. 8499\n",
       "96            ALDO          Textured Block Sandals                   Rs. 7999\n",
       "97  Tommy Hilfiger            Men Leather Sneakers  Rs. 6509Rs. 9299(30% OFF)\n",
       "98            ALDO  Women Leather Horsebit Loafers                  Rs. 11999\n",
       "99         fitflop    Embellished PU Comfort Pumps                   Rs. 7499\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating dataframe for the first 100 shoes\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['Brand'] = brand[0:100]\n",
    "df['Shoe Description'] = shoe_description[0:100]\n",
    "df['Price'] = price[0:100]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d94ed4d",
   "metadata": {},
   "source": [
    "<b>Q8: Go to webpage https://www.amazon.in/             \n",
    "Enter “Laptop” in the search field and then click the search icon.           \n",
    "Then set CPU Type filter to “Intel Core i7” as shown in the below image:</b>\n",
    "\n",
    "<b>After setting the filters scrape first 10 laptops data. You have to scrape 3 attributesfor each laptop:</b>      \n",
    "<b>1. Title</b>           \n",
    "<b>2. Ratings</b>          \n",
    "<b>3. Price</b>\n",
    "\n",
    "<b>Note: All the steps required during scraping should be done through code only and not manually.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "35816f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets first connect to the driver\n",
    "\n",
    "driver = webdriver.Chrome(r\"C:\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "123e9cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the webpage on automated chrome browser\n",
    "\n",
    "driver.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fa55c506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering “Laptop” in the search field\n",
    "\n",
    "product = driver.find_element(By.XPATH,\"//div[@class='nav-search-field ']/input\")\n",
    "product.send_keys('laptop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "71ac165a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking the search button\n",
    "\n",
    "search = driver.find_element(By.XPATH,\"//div[@class='nav-search-submit nav-sprite']\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "00fde331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the CPU Type filter Intel Core i7 by clicking it\n",
    "\n",
    "CPU_filter = driver.find_element(By.XPATH,'//span[@class=\"a-size-base a-color-base\"]')\n",
    "CPU_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4b71a644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty lists for scraping data\n",
    "\n",
    "title = []\n",
    "ratings = []\n",
    "price = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3b4cbf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting all the tags\n",
    "\n",
    "product_title = driver.find_elements(By.XPATH,'//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "for i in product_title:\n",
    "    title.append(i.text)\n",
    "    \n",
    "product_ratings = driver.find_elements(By.XPATH,'//div[@class=\"a-row a-size-small\"]/span')\n",
    "for i in product_ratings:\n",
    "    ratings.append(i.get_attribute(\"aria-label\"))\n",
    "    \n",
    "product_price = driver.find_elements(By.XPATH,'//span[@class=\"a-price-whole\"]')\n",
    "for i in product_price:\n",
    "    price.append(i.text) \n",
    "        \n",
    "time.sleep(3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c1f76ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting rating from the unorganised ratings tag\n",
    "\n",
    "rating = []\n",
    "for i in range(0,len(ratings)):\n",
    "    if i == 0 or  i/2 == i//2:\n",
    "        rating.append(ratings[i][0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f7724495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acer Extensa 15 Lightweight Laptop 11th Gen In...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>38,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dell Vostro 3420 Laptop - Intel i3-1115G4, 8GB...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>42,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, A...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Renewed) Lenovo Thinkpad E480 7th Gen Intel C...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASUS Vivobook 15, 15.6\" (39.62 cm) FHD, AMD Du...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>40,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HP Chromebook 14a,Intel Celeron N4500 14inch(3...</td>\n",
       "      <td>3.6</td>\n",
       "      <td>19,599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dell Inspiron 15 (3501) 15.6 inches FHD Displa...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>34,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(Renewed) Dell Latitude E5470 Intel Core i5 6t...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>21,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lenovo IdeaPad Slim 1 Intel Celeron N4020 4th ...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>41,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lenovo IdeaPad Slim 3 Intel Celeron N4020 4th ...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>21,550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title Ratings   Price\n",
       "0  Acer Extensa 15 Lightweight Laptop 11th Gen In...     4.2  38,990\n",
       "1  Dell Vostro 3420 Laptop - Intel i3-1115G4, 8GB...     4.1  42,990\n",
       "2  ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, A...     4.0  37,999\n",
       "3  (Renewed) Lenovo Thinkpad E480 7th Gen Intel C...     4.0  32,990\n",
       "4  ASUS Vivobook 15, 15.6\" (39.62 cm) FHD, AMD Du...     5.0  40,490\n",
       "5  HP Chromebook 14a,Intel Celeron N4500 14inch(3...     3.6  19,599\n",
       "6  Dell Inspiron 15 (3501) 15.6 inches FHD Displa...     3.8  34,990\n",
       "7  (Renewed) Dell Latitude E5470 Intel Core i5 6t...     3.8  21,990\n",
       "8  Lenovo IdeaPad Slim 1 Intel Celeron N4020 4th ...     3.8  41,999\n",
       "9  Lenovo IdeaPad Slim 3 Intel Celeron N4020 4th ...     4.2  21,550"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating dataframe for the first 10 laptops\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['Title'] = title[0:10]\n",
    "df['Ratings'] = rating[0:10]\n",
    "df['Price'] = price[0:10]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e8bc10",
   "metadata": {},
   "source": [
    "<b>Q9: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida\n",
    "location. You have to scrape company name, No. of days ago when job was posted, Rating of the company.</b>\n",
    "\n",
    "<b>This task will be done in following steps:</b>         \n",
    "<b>1. First get the webpage https://www.ambitionbox.com/</b>           \n",
    "<b>2. Click on the Job option as shown in the image</b>         \n",
    "<b>3. After reaching to the next webpage, In place of “Search by Designations, Companies, Skills” enter\n",
    "“Data Scientist” and click on search button.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2e4dbe1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As suggested, I have skipped this question as there is some technical issue of the site."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184a382c",
   "metadata": {},
   "source": [
    "<b>Q10: Write a python program to scrape the salary data for Data Scientist designation.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary.</b>\n",
    "\n",
    "<b>The above task will be, done as shown in the below steps:</b>          \n",
    "<b>1. First get the webpage https://www.ambitionbox.com/</b>         \n",
    "<b>2. Click on the salaries option as shown in the image.</b>         \n",
    "<b>3. After reaching to the following webpage, In place of “Search Job Profile” enters “Data Scientist” and then click on “Data Scientist”.</b>          \n",
    "<b>You have to scrape the data ticked in the above image.</b>      \n",
    "<b>4. Scrape the data for the first 10 companies. Scrape the company name, total salary record, average\n",
    "salary, minimum salary, maximum salary, experience required.</b>          \n",
    "<b>5. Store the data in a dataframe.</b>\n",
    "\n",
    "<b>Note: All the steps required during scraping should be done through code only and not manually.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "df2b4e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets first connect to the driver\n",
    "\n",
    "driver = webdriver.Chrome(r\"C:\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e48bb432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the webpage on automated chrome browser\n",
    "\n",
    "driver.get(\"https://www.ambitionbox.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2ca11972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on the Salary webpage\n",
    "\n",
    "salaries = driver.find_element(By.XPATH,'//ul[@class=\"nav-list-wrapper\"]/li[3]')\n",
    "salaries.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2f561341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the url of the required webpage\n",
    "\n",
    "driver.get(\"https://www.ambitionbox.com/salaries?campaign=desktop_nav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "78ce0d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty lists for scraping data\n",
    "\n",
    "company_name = []\n",
    "salary_record = []\n",
    "average_salary = []\n",
    "min_salary = []\n",
    "max_salary = []\n",
    "exp = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "deff5e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting all the tags\n",
    "\n",
    "company = driver.find_elements(By.XPATH,\"//div[@class='company-info']\")\n",
    "for i in company:\n",
    "    company_name.append(i.text.split(\"\\n\")[0])                                                    #company name\n",
    "    salary_record.append(i.text.replace(\"based on\", \" \").replace(\"salaries\",\"\").split(\"\\n\")[1:2]) #Total Salary Record\n",
    "    exp.append(i.text.replace(\"yrs exp\",\"\").replace(\"yr exp\",\"\").split(\"\\n\")[-1])                 # Experience required\n",
    "    \n",
    "\n",
    "avg_salary = driver.find_elements(By.XPATH,\"//div[@class='average-indicator-wrapper']\")\n",
    "for i in avg_salary:\n",
    "    average_salary.append(i.text.replace(\"₹\",\"\").replace(\"L\",\"\"))            # average salary\n",
    "\n",
    "\n",
    "salary = driver.find_elements(By.XPATH,\"//div[@class='salary-values']\")\n",
    "for i in salary:\n",
    "    min_salary.append(i.text.replace(\"₹\",\"\").replace(\"L\",\"\").split(\"\\n\")[0])  # minimum salary\n",
    "    max_salary.append(i.text.replace(\"₹\",\"\").replace(\"L\",\"\").split(\"\\n\")[1])  # maximum salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "58887ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Total_Salary_Record</th>\n",
       "      <th>Experience_Required</th>\n",
       "      <th>Average_Salary_L</th>\n",
       "      <th>Minimum_Salary_L</th>\n",
       "      <th>Maximum_Salary_L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Google</td>\n",
       "      <td>[Software Engineer Salary]</td>\n",
       "      <td>1-4 erience (based on 63 salaries)</td>\n",
       "      <td>34.9</td>\n",
       "      <td>12.7</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Microsoft Corporation</td>\n",
       "      <td>[Software Engineer Salary]</td>\n",
       "      <td>1-4 erience (based on 344 salaries)</td>\n",
       "      <td>23.9</td>\n",
       "      <td>13.2</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Goldman Sachs</td>\n",
       "      <td>[Software Engineer Salary]</td>\n",
       "      <td>1-2 erience (based on 37 salaries)</td>\n",
       "      <td>22.7</td>\n",
       "      <td>12.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arista Networks</td>\n",
       "      <td>[Software Engineer Salary]</td>\n",
       "      <td>1-4 erience (based on 52 salaries)</td>\n",
       "      <td>22.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tekion</td>\n",
       "      <td>[Software Engineer Salary]</td>\n",
       "      <td>2-4 erience (based on 52 salaries)</td>\n",
       "      <td>21.9</td>\n",
       "      <td>11.7</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>[Software Engineer Salary]</td>\n",
       "      <td>1-4 erience (based on 147 salaries)</td>\n",
       "      <td>21.2</td>\n",
       "      <td>8.7</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Servicenow Software Development India</td>\n",
       "      <td>[Software Engineer Salary]</td>\n",
       "      <td>2-4 erience (based on 82 salaries)</td>\n",
       "      <td>21.1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>[Software Engineer Salary]</td>\n",
       "      <td>1-4 erience (based on 112 salaries)</td>\n",
       "      <td>20.3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>32.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PayPal</td>\n",
       "      <td>[Software Engineer Salary]</td>\n",
       "      <td>1-2 erience (based on 31 salaries)</td>\n",
       "      <td>19.9</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Arcesium</td>\n",
       "      <td>[Software Engineer Salary]</td>\n",
       "      <td>1-2 erience (based on 71 salaries)</td>\n",
       "      <td>19.4</td>\n",
       "      <td>12.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Company_Name         Total_Salary_Record  \\\n",
       "0                                 Google  [Software Engineer Salary]   \n",
       "1                  Microsoft Corporation  [Software Engineer Salary]   \n",
       "2                          Goldman Sachs  [Software Engineer Salary]   \n",
       "3                        Arista Networks  [Software Engineer Salary]   \n",
       "4                                 Tekion  [Software Engineer Salary]   \n",
       "5                                 Amazon  [Software Engineer Salary]   \n",
       "6  Servicenow Software Development India  [Software Engineer Salary]   \n",
       "7                                Walmart  [Software Engineer Salary]   \n",
       "8                                 PayPal  [Software Engineer Salary]   \n",
       "9                               Arcesium  [Software Engineer Salary]   \n",
       "\n",
       "                   Experience_Required Average_Salary_L Minimum_Salary_L  \\\n",
       "0   1-4 erience (based on 63 salaries)             34.9             12.7   \n",
       "1  1-4 erience (based on 344 salaries)             23.9             13.2   \n",
       "2   1-2 erience (based on 37 salaries)             22.7             12.0   \n",
       "3   1-4 erience (based on 52 salaries)             22.1              5.0   \n",
       "4   2-4 erience (based on 52 salaries)             21.9             11.7   \n",
       "5  1-4 erience (based on 147 salaries)             21.2              8.7   \n",
       "6   2-4 erience (based on 82 salaries)             21.1             14.0   \n",
       "7  1-4 erience (based on 112 salaries)             20.3             12.0   \n",
       "8   1-2 erience (based on 31 salaries)             19.9             12.0   \n",
       "9   1-2 erience (based on 71 salaries)             19.4             12.0   \n",
       "\n",
       "  Maximum_Salary_L  \n",
       "0             97.0  \n",
       "1             50.0  \n",
       "2             34.0  \n",
       "3             38.0  \n",
       "4             38.0  \n",
       "5             45.0  \n",
       "6             32.0  \n",
       "7             32.5  \n",
       "8             31.0  \n",
       "9             34.0  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating dataframe for the first 10 companies\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['Company_Name'] = company_name[0:10]\n",
    "df['Total_Salary_Record'] = salary_record[0:10]\n",
    "df['Experience_Required'] = exp[0:10]\n",
    "df['Average_Salary_L'] = average_salary[0:10]\n",
    "df['Minimum_Salary_L'] = min_salary\n",
    "df['Maximum_Salary_L'] = max_salary\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6869634b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
